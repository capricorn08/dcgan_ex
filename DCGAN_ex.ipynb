{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "from keras import backend as K\n",
    "from skimage.io import imread\n",
    "from datetime import datetime\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from datetime import datetime as dt\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "plt.rcParams[\"axes.grid\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['path', 'angle', 'pos', 'datetime', 'cc', 'row', 'col', 'label'])\n",
    "files = sorted(glob(\"img2/*/*/*/*/*\"))\n",
    "for f in files:\n",
    "    f_name = f.split(\"CAM_\")[1].split(\"_\")\n",
    "    df.loc[len(df)] = [f, f_name[0], f_name[1], \"-\".join(f_name[2:5]),\n",
    "                       f_name[5][5:], f_name[6][3:], f_name[7][3:-1], f[5:7]]\n",
    "    \n",
    "df['datetime_id'] = df['datetime']\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], format=\"%Y%m%d-%H%M%S-%f\")\n",
    "df['cc'].replace('', np.NaN, inplace=True)\n",
    "for i in range(0,len(df)):\n",
    "    df['datetime_id'][i]= df['datetime_id'][i].replace(\"-\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_preproc(angle='Z', label='NG'):\n",
    "    sqr_img = []\n",
    "    path_list = []\n",
    "    for idx, path in enumerate(df[(df['angle']==angle) & (df['label']==label)]['path']):\n",
    "        img = cv2.imread(path)\n",
    "    \n",
    "        # convert img to square\n",
    "        height, width, _ = img.shape\n",
    "        size = max(height, width)\n",
    "        empty_img = np.zeros((size, size, 3), np.uint8)\n",
    "\n",
    "        x_offset = int((size - width) / 2)\n",
    "        y_offset = int((size - height) / 2)\n",
    "        empty_img[y_offset : y_offset + height, x_offset : x_offset + width] = img\n",
    "\n",
    "        empty_img = cv2.resize(empty_img, (size, size), interpolation=cv2.INTER_CUBIC)\n",
    "        sqr_img.append(cv2.cvtColor(empty_img, cv2.COLOR_BGR2RGB))\n",
    "        path_list.append(path)\n",
    "        \n",
    "    return sqr_img, path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_ng, path_list_up_ng = input_preproc(angle='UP', label='NG')\n",
    "up_ok, path_list_up_ok = input_preproc(angle='UP', label='OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# detection_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import operator\n",
    "\n",
    "def detection_y(data,path_list):\n",
    "    cnt_1 = 0\n",
    "    img_detection = np.empty((0, 100, 200, 3), dtype='uint8') # empty array to append img\n",
    "    ##for i in up_ok[1400:1410] pos3\n",
    "    for i in data:\n",
    "        img_color = copy.deepcopy(i)\n",
    "        string_path = path_list[cnt_1]\n",
    "\n",
    "        #input_data = cv2.fastNlMeansDenoisingColored(img_color.copy(),None,7,7,7,13)\n",
    "        # BGR(파랑색)\n",
    "        #color = [255, 0, 0]\n",
    "#         color = [50, 255, 255]\n",
    "#         pixel = np.uint8([[color]])\n",
    "#         # cvtColor를 사용하여 HSV 색공간으로 변환한다.\n",
    "#         hsv = cv2.cvtColor(pixel, cv2.COLOR_BGR2HSV)\n",
    "#         # HSV값을 출력하기위해 픽셀값만 갖고온다.\n",
    "#         hsv = hsv[0][0]\n",
    "\n",
    "        # bgr과 hsv 값 출력\n",
    "        #print(\"bgr: \", color)\n",
    "        #print(\"hsv: \", hsv)\n",
    "\n",
    "        # 이미지파일을 컬러로 읽어온다.\n",
    "        #img_color = cv2.imread('food.jpg')\n",
    "\n",
    "        # 이미지의 높이와 너비를 갖고온다.\n",
    "        height,width = img_color.shape[:2]\n",
    "        shape = img_color.shape[0]\n",
    "        #print(shape)\n",
    "\n",
    "        # hsv이미지로 변환한다.\n",
    "        img_hsv = cv2.cvtColor(img_color.copy(), cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # 범위를 정하여 hsv이미지에서 원하는 색 영역을 바이너리 이미지로 생성한다.\n",
    "        # (가운데와 마지막값은 너무어두워서 검은색에 가까운색과 너무 옅어서 흰색에 가까운색을 제외시키기위해 30으로해야한다.\n",
    "        #lower_blue = (120-10, 30, 30)\n",
    "        #upper_blue = (120+10, 255, 255)\n",
    "        # yellow color upper and lower bound   \n",
    "\n",
    "        # 앞서 선언한 범위값을 사용하여 바이너리 이미지를 얻는다.(범위내에 있는 픽셀들은 흰색이되고 나머지는 검은색이 된다.)\n",
    "        mask1 = cv2.inRange(img_hsv.copy(), (60,60,60), (180, 200, 200))\n",
    "        kernel = np.ones((2,2),np.uint8)        \n",
    "        dilation = cv2.dilate(mask1.copy(),kernel,iterations = 1)\n",
    "        opening = cv2.morphologyEx(dilation.copy(), cv2.MORPH_OPEN, kernel)\n",
    "        #closing = cv2.morphologyEx(opening.copy(), cv2.MORPH_CLOSE, kernel)\n",
    "        _, thresh = cv2.threshold(opening, 60, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "        bluecnts2 = cv2.findContours(thresh,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "\n",
    "        img_color2 = copy.deepcopy(img_color)\n",
    "\n",
    "        list_val = []        \n",
    "        for cnt in bluecnts2:                        \n",
    "            x2, y2, w2, h2 = cv2.boundingRect(cnt)\n",
    "            area_x = cv2.contourArea(cnt)\n",
    "            rect2 = cv2.rectangle(img_color2, (x2, y2), (x2 + w2, y2 + h2), (0,255,0), 1)        \n",
    "            list_val.append(area_x)\n",
    "\n",
    "        index1, value1 = max(enumerate(list_val), key=operator.itemgetter(1))\n",
    "        index2 = []\n",
    "        ex_list = [[],[]]\n",
    "        count_num = 0\n",
    "        #print('contour length = ', len(bluecnts2))\n",
    "        for cnt in bluecnts2:                                \n",
    "            area_x = cv2.contourArea(cnt)\n",
    "            if (value1/4) < area_x:#  or (value1/) < area_x:\n",
    "                index2.append(count_num)            \n",
    "                ex_list[0].append(cnt)            \n",
    "                ex_list[1].append(area_x)            \n",
    "            count_num = count_num + 1\n",
    "\n",
    "        img_color3 = copy.deepcopy(img_color)\n",
    "        img_color4 = copy.deepcopy(img_color)\n",
    "        #print('counts of rectangle = ',index2)\n",
    "        #index2.sort(reverse=True)\n",
    "        #print('[0] = ',ex_list[0])\n",
    "        #print('[1] = ',ex_list[1])\n",
    "        if len(index2) > 1 :\n",
    "            for cnt in index2:                        \n",
    "                x3, y3, w3, h3 = cv2.boundingRect(bluecnts2[cnt])        \n",
    "                rect3 = cv2.rectangle(img_color3, (x3, y3), (x3 + w3, y3 + h3), (0,255,0), 1)\n",
    "\n",
    "            x5, y5, w5, h5 = cv2.boundingRect(bluecnts2[index2[0]])        \n",
    "            x6, y6, w6, h6 = cv2.boundingRect(bluecnts2[index2[1]])\n",
    "            x7 = 0 \n",
    "            y7 = 0\n",
    "            w7 = 0\n",
    "            h7 =0\n",
    "            x8 = 0 \n",
    "            y8 = 0\n",
    "            if x5 > x6:\n",
    "                x7 = x6\n",
    "            else:\n",
    "                x7 = x5\n",
    "\n",
    "            if y5 < y6:\n",
    "                y7 = y5\n",
    "            else:\n",
    "                y7 = y6\n",
    "\n",
    "\n",
    "            if x5 + w5 < x6 + w6:\n",
    "                x8 = x6\n",
    "                w7 = w6        \n",
    "            else:\n",
    "                x8 = x5\n",
    "                w7 = w5\n",
    "\n",
    "            if y5 + h5 < y6 + h6:\n",
    "                y8 = y6\n",
    "                h7 = h6\n",
    "\n",
    "            else:\n",
    "                y8 = y5\n",
    "                h7 = h5\n",
    "\n",
    "            rect4 = cv2.rectangle(img_color4, (x7-10, y7-20), (x8 + w7+10, y8 + h7+10), (0,255,0), 2)\n",
    "#             fontface = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#             scale = 0.6\n",
    "#             thickness = 2\n",
    "#             size = cv2.getTextSize(string_path, fontface, scale, thickness)\n",
    "#             text_width = size[0][0]\n",
    "#             text_height = size[0][1]\n",
    "#             pt = (x7 + int((w7 - text_width) / 2), y7 + int((h7 + text_height) / 2))\n",
    "#             cv2.putText(img_color, string_path, pt, fontface, scale, (255, 255, 255), thickness, 8)\n",
    "            img_resized_1 = img_color[y7-20:y8 + h7+10, x7-10: x8 + w7+10] # crop\n",
    "            try:\n",
    "                img_resized_2 = cv2.resize(img_resized_1.copy(), (200, 100), interpolation=cv2.INTER_CUBIC)\n",
    "                cnt_1 = cnt_1 + 1 \n",
    "            except:\n",
    "                img_resized_1 = img_color[y7:y8 + h7, x7: x8 + w7] # crop\n",
    "                img_resized_2 = cv2.resize(img_resized_1.copy(), (200, 100), interpolation=cv2.INTER_CUBIC)\n",
    "                cnt_1 = cnt_1 + 1 \n",
    "                \n",
    "\n",
    "#             except:\n",
    "#                 img_re = img_resized(img_color.copy(),x7,y7,w7,h7)\n",
    "#                 img_resized_2 = cv2.resize(img_re.copy(), (200, 100), interpolation=cv2.INTER_CUBIC)\n",
    "#                 print('*'*135)\n",
    "#                 plt.imshow(img_resized_2)\n",
    "#                 plt.show()\n",
    "#                 print('*'*135)\n",
    "            \n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            arr = []\n",
    "            for cnt in index2:                        \n",
    "                x3, y3, w3, h3 = cv2.boundingRect(bluecnts2[cnt])\n",
    "                #if (shape/2) > (x3 + w3 + 10):                    \n",
    "                rect4 = cv2.rectangle(img_color4, (x3-10, y3-20), (x3 + w3 + 10, y3 + h3 + 20), (0,255,0), 2)    \n",
    "                img_resized_1 = img_color[y3-20:y3 + h3 + 20, x3-10:x3 + w3 + 10] # crop\n",
    "                img_resized_2 = cv2.resize(img_resized_1.copy(), (200, 100), interpolation=cv2.INTER_CUBIC)\n",
    "                x2, y2, w2, h2 = cv2.boundingRect(bluecnts2[cnt])\n",
    "                rect2 = cv2.rectangle(img_color2.copy(), (x2, y2), (x2 + w2, y2 + h2), (0,255,0), 1)\n",
    "                print(cnt_1)\n",
    "                cnt_1 = cnt_1 + 1 \n",
    "                print(string_path)\n",
    "                #print(bluecnts2[cnt])\n",
    "                #### convert contour to rectangles\n",
    "                xywh = []\n",
    "                for cnt1 in bluecnts2[cnt]:\n",
    "                # ___________________________________________________________________________________ 컨투어 사각형 좌표 리턴\n",
    "                    _x, _y, _w, _h = np.array(cv2.boundingRect(cnt1) + np.array([-5,-10,10,20])) # add padding to rectangles\n",
    "                # ___________________________________________________________________________________\n",
    "                    xywh.append(list(map(int, [_x, _y, _w, _h])))\n",
    "                # _______________________________________________________________________________________ 중복 사각형 병합\n",
    "                rect, _ = cv2.groupRectangles(xywh+xywh, 0, 0.001) # merge contours with intersection\n",
    "                # _______________________________________________________________________________________\n",
    "                print('o'*135)\n",
    "                plt.figure(figsize=(30,10))    \n",
    "                plt.subplot(1,4,1)\n",
    "                plt.imshow(rect2)\n",
    "                plt.subplot(1,4,2)\n",
    "                plt.imshow(rect4)\n",
    "                plt.subplot(1,4,3)\n",
    "                plt.imshow(rect)\n",
    "                plt.subplot(1,4,4)\n",
    "                plt.imshow(img_resized_2)\n",
    "                plt.show()\n",
    "                print('o'*135)\n",
    "\n",
    "        img_detection = np.concatenate((img_detection, img_resized_2[np.newaxis,...]), axis=0)        \n",
    "        print(cnt_1)\n",
    "        temp = string_path[0:-4].split('CAM_')        \n",
    "#        cv2.imwrite('img//UP_OK_2/{}.jpg'.format(temp[1]), cv2.cvtColor(img_resized_2, cv2.COLOR_RGB2BGR))        \n",
    "        print(string_path)\n",
    "#         plt.figure(figsize=(30,10))    \n",
    "#         plt.subplot(1,4,1)\n",
    "#         plt.imshow(img_color)\n",
    "#         plt.subplot(1,4,2)\n",
    "#         plt.imshow(rect2)\n",
    "#         plt.subplot(1,4,3)\n",
    "#         plt.imshow(rect3)\n",
    "#         plt.subplot(1,4,4)\n",
    "#         plt.imshow(rect4) \n",
    "#         plt.subplot(1,6,5)\n",
    "#         plt.imshow(dilation)\n",
    "#         plt.subplot(1,6,6)\n",
    "#         plt.imshow(img_resized_2) \n",
    "        plt.show()\n",
    "        print('='*135)\n",
    "        \n",
    "\n",
    "    return img_detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import operator\n",
    "\n",
    "def detection_y_1(data,path_list):\n",
    "    cnt_1 = 0\n",
    "    img_detection = np.empty((0, 48, 100, 3), dtype='uint8') # empty array to append img\n",
    "    ##for i in up_ok[1400:1410] pos3\n",
    "    for i in data:\n",
    "        img_color = copy.deepcopy(i)\n",
    "        string_path = path_list[cnt_1]\n",
    "\n",
    "        #input_data = cv2.fastNlMeansDenoisingColored(img_color.copy(),None,7,7,7,13)\n",
    "        # BGR(파랑색)\n",
    "        #color = [255, 0, 0]\n",
    "#         color = [50, 255, 255]\n",
    "#         pixel = np.uint8([[color]])\n",
    "#         # cvtColor를 사용하여 HSV 색공간으로 변환한다.\n",
    "#         hsv = cv2.cvtColor(pixel, cv2.COLOR_BGR2HSV)\n",
    "#         # HSV값을 출력하기위해 픽셀값만 갖고온다.\n",
    "#         hsv = hsv[0][0]\n",
    "\n",
    "        # bgr과 hsv 값 출력\n",
    "        #print(\"bgr: \", color)\n",
    "        #print(\"hsv: \", hsv)\n",
    "\n",
    "        # 이미지파일을 컬러로 읽어온다.\n",
    "        #img_color = cv2.imread('food.jpg')\n",
    "\n",
    "        # 이미지의 높이와 너비를 갖고온다.\n",
    "        height,width = img_color.shape[:2]\n",
    "        shape = img_color.shape[0]\n",
    "        #print(shape)\n",
    "\n",
    "        # hsv이미지로 변환한다.\n",
    "        img_hsv = cv2.cvtColor(img_color.copy(), cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # 범위를 정하여 hsv이미지에서 원하는 색 영역을 바이너리 이미지로 생성한다.\n",
    "        # (가운데와 마지막값은 너무어두워서 검은색에 가까운색과 너무 옅어서 흰색에 가까운색을 제외시키기위해 30으로해야한다.\n",
    "        #lower_blue = (120-10, 30, 30)\n",
    "        #upper_blue = (120+10, 255, 255)\n",
    "        # yellow color upper and lower bound   \n",
    "\n",
    "        # 앞서 선언한 범위값을 사용하여 바이너리 이미지를 얻는다.(범위내에 있는 픽셀들은 흰색이되고 나머지는 검은색이 된다.)\n",
    "        mask1 = cv2.inRange(img_hsv.copy(), (60,60,60), (180, 200, 200))\n",
    "        kernel = np.ones((2,2),np.uint8)        \n",
    "        dilation = cv2.dilate(mask1.copy(),kernel,iterations = 1)\n",
    "        opening = cv2.morphologyEx(dilation.copy(), cv2.MORPH_OPEN, kernel)\n",
    "        #closing = cv2.morphologyEx(opening.copy(), cv2.MORPH_CLOSE, kernel)\n",
    "        _, thresh = cv2.threshold(opening, 60, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "        bluecnts2 = cv2.findContours(thresh,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "\n",
    "        img_color2 = copy.deepcopy(img_color)\n",
    "\n",
    "        list_val = []        \n",
    "        for cnt in bluecnts2:                        \n",
    "            x2, y2, w2, h2 = cv2.boundingRect(cnt)\n",
    "            area_x = cv2.contourArea(cnt)\n",
    "            rect2 = cv2.rectangle(img_color2, (x2, y2), (x2 + w2, y2 + h2), (0,255,0), 1)        \n",
    "            list_val.append(area_x)\n",
    "\n",
    "        index1, value1 = max(enumerate(list_val), key=operator.itemgetter(1))\n",
    "        index2 = []\n",
    "        ex_list = [[],[]]\n",
    "        count_num = 0\n",
    "        #print('contour length = ', len(bluecnts2))\n",
    "        for cnt in bluecnts2:                                \n",
    "            area_x = cv2.contourArea(cnt)\n",
    "            if (value1/4) < area_x:#  or (value1/) < area_x:\n",
    "                index2.append(count_num)            \n",
    "                ex_list[0].append(cnt)            \n",
    "                ex_list[1].append(area_x)            \n",
    "            count_num = count_num + 1\n",
    "\n",
    "        img_color3 = copy.deepcopy(img_color)\n",
    "        img_color4 = copy.deepcopy(img_color)\n",
    "        #print('counts of rectangle = ',index2)\n",
    "        #index2.sort(reverse=True)\n",
    "        #print('[0] = ',ex_list[0])\n",
    "        #print('[1] = ',ex_list[1])\n",
    "        if len(index2) > 1 :\n",
    "            for cnt in index2:                        \n",
    "                x3, y3, w3, h3 = cv2.boundingRect(bluecnts2[cnt])        \n",
    "                rect3 = cv2.rectangle(img_color3, (x3, y3), (x3 + w3, y3 + h3), (0,255,0), 1)\n",
    "\n",
    "            x5, y5, w5, h5 = cv2.boundingRect(bluecnts2[index2[0]])        \n",
    "            x6, y6, w6, h6 = cv2.boundingRect(bluecnts2[index2[1]])\n",
    "            x7 = 0 \n",
    "            y7 = 0\n",
    "            w7 = 0\n",
    "            h7 =0\n",
    "            x8 = 0 \n",
    "            y8 = 0\n",
    "            if x5 > x6:\n",
    "                x7 = x6\n",
    "            else:\n",
    "                x7 = x5\n",
    "\n",
    "            if y5 < y6:\n",
    "                y7 = y5\n",
    "            else:\n",
    "                y7 = y6\n",
    "\n",
    "\n",
    "            if x5 + w5 < x6 + w6:\n",
    "                x8 = x6\n",
    "                w7 = w6        \n",
    "            else:\n",
    "                x8 = x5\n",
    "                w7 = w5\n",
    "\n",
    "            if y5 + h5 < y6 + h6:\n",
    "                y8 = y6\n",
    "                h7 = h6\n",
    "\n",
    "            else:\n",
    "                y8 = y5\n",
    "                h7 = h5\n",
    "\n",
    "            rect4 = cv2.rectangle(img_color4, (x7-10, y7-20), (x8 + w7+10, y8 + h7+10), (0,255,0), 2)\n",
    "#             fontface = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#             scale = 0.6\n",
    "#             thickness = 2\n",
    "#             size = cv2.getTextSize(string_path, fontface, scale, thickness)\n",
    "#             text_width = size[0][0]\n",
    "#             text_height = size[0][1]\n",
    "#             pt = (x7 + int((w7 - text_width) / 2), y7 + int((h7 + text_height) / 2))\n",
    "#             cv2.putText(img_color, string_path, pt, fontface, scale, (255, 255, 255), thickness, 8)\n",
    "            img_resized_1 = img_color[y7-20:y8 + h7+10, x7-10: x8 + w7+10] # crop\n",
    "            try:\n",
    "                img_resized_2 = cv2.resize(img_resized_1.copy(), (100, 48), interpolation=cv2.INTER_CUBIC)\n",
    "                cnt_1 = cnt_1 + 1 \n",
    "            except:\n",
    "                img_resized_1 = img_color[y7:y8 + h7, x7: x8 + w7] # crop\n",
    "                img_resized_2 = cv2.resize(img_resized_1.copy(), (100, 48), interpolation=cv2.INTER_CUBIC)\n",
    "                cnt_1 = cnt_1 + 1 \n",
    "                \n",
    "\n",
    "#             except:\n",
    "#                 img_re = img_resized(img_color.copy(),x7,y7,w7,h7)\n",
    "#                 img_resized_2 = cv2.resize(img_re.copy(), (200, 100), interpolation=cv2.INTER_CUBIC)\n",
    "#                 print('*'*135)\n",
    "#                 plt.imshow(img_resized_2)\n",
    "#                 plt.show()\n",
    "#                 print('*'*135)\n",
    "            \n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            arr = []\n",
    "            for cnt in index2:                        \n",
    "                x3, y3, w3, h3 = cv2.boundingRect(bluecnts2[cnt])\n",
    "                #if (shape/2) > (x3 + w3 + 10):                    \n",
    "                rect4 = cv2.rectangle(img_color4, (x3-10, y3-20), (x3 + w3 + 10, y3 + h3 + 20), (0,255,0), 2)    \n",
    "                img_resized_1 = img_color[y3-20:y3 + h3 + 20, x3-10:x3 + w3 + 10] # crop\n",
    "                img_resized_2 = cv2.resize(img_resized_1.copy(), (100, 48), interpolation=cv2.INTER_CUBIC)\n",
    "                x2, y2, w2, h2 = cv2.boundingRect(bluecnts2[cnt])\n",
    "                rect2 = cv2.rectangle(img_color2.copy(), (x2, y2), (x2 + w2, y2 + h2), (0,255,0), 1)\n",
    "                print(cnt_1)\n",
    "                cnt_1 = cnt_1 + 1 \n",
    "                print(string_path)\n",
    "                #print(bluecnts2[cnt])\n",
    "                #### convert contour to rectangles\n",
    "                xywh = []\n",
    "                for cnt1 in bluecnts2[cnt]:\n",
    "                # ___________________________________________________________________________________ 컨투어 사각형 좌표 리턴\n",
    "                    _x, _y, _w, _h = np.array(cv2.boundingRect(cnt1) + np.array([-5,-10,10,20])) # add padding to rectangles\n",
    "                # ___________________________________________________________________________________\n",
    "                    xywh.append(list(map(int, [_x, _y, _w, _h])))\n",
    "                # _______________________________________________________________________________________ 중복 사각형 병합\n",
    "                rect, _ = cv2.groupRectangles(xywh+xywh, 0, 0.001) # merge contours with intersection\n",
    "                # _______________________________________________________________________________________\n",
    "                print('o'*135)\n",
    "                plt.figure(figsize=(30,10))    \n",
    "                plt.subplot(1,4,1)\n",
    "                plt.imshow(rect2)\n",
    "                plt.subplot(1,4,2)\n",
    "                plt.imshow(rect4)\n",
    "                plt.subplot(1,4,3)\n",
    "                plt.imshow(rect)\n",
    "                plt.subplot(1,4,4)\n",
    "                plt.imshow(img_resized_2)\n",
    "                plt.show()\n",
    "                print('o'*135)\n",
    "\n",
    "        img_detection = np.concatenate((img_detection, img_resized_2[np.newaxis,...]), axis=0)        \n",
    "        print(cnt_1)\n",
    "        temp = string_path[0:-4].split('CAM_')        \n",
    "#        cv2.imwrite('img//UP_OK_2/{}.jpg'.format(temp[1]), cv2.cvtColor(img_resized_2, cv2.COLOR_RGB2BGR))        \n",
    "        print(string_path)\n",
    "#         plt.figure(figsize=(30,10))    \n",
    "#         plt.subplot(1,4,1)\n",
    "#         plt.imshow(img_color)\n",
    "#         plt.subplot(1,4,2)\n",
    "#         plt.imshow(rect2)\n",
    "# #         plt.subplot(1,4,3)\n",
    "# #         plt.imshow(rect3)\n",
    "#         plt.subplot(1,4,3)\n",
    "#         plt.imshow(dilation) \n",
    "#         plt.subplot(1,4,4)\n",
    "#         plt.imshow(img_resized_2) \n",
    "#         plt.show()\n",
    "        print('='*135)\n",
    "        \n",
    "\n",
    "    return img_detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# detectiony_50_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_up_ok_det = detection_y(up_ok, path_list_up_ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_up_ng_det = detection_y(up_ng, path_list_up_ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_up_ok_det = detection_y_1(up_ok, path_list_up_ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_up_ng_det = detection_y_1(up_ng, path_list_up_ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_up_ok_det.shape, img_up_ng_det.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((img_up_ng_det, img_up_ok_det))\n",
    "y = np.concatenate((np.ones(len(img_up_ng_det)), np.zeros(len(img_up_ok_det))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grayscale\n",
    "#X = X[:,:,:,-1]\n",
    "#X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers, metrics\n",
    "from keras.layers import Input, Dense, Conv2D, Activation, GlobalAveragePooling2D, Flatten, concatenate\n",
    "from keras.layers import Dropout, BatchNormalization, MaxPooling2D, Lambda\n",
    "from keras.models import Model, Input\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.mobilenetv2 import MobileNetV2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import multi_gpu_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "import pydot as pyd\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 48\n",
    "        self.img_cols = 100\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        #optimizer = Adam(0.0008, 0.5)\n",
    "        optimizer = RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        \n",
    "        # Generator의 결과는 이미지 입니다.\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        # Generator와 Discriminator를 동시에 학습시키고 싶을 때 trainable을 False로 설정\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity        \n",
    "        # Discriminator의 결과는 이미지가 진짜인지 가짜인지에 대한 확률입니다.\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        optimizer = RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined = multi_gpu_model(self.combined, gpus=2)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 12 * 25 , activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((12, 25, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        \n",
    "        #model.add(Flatten())\n",
    "        model.add(GlobalAveragePooling2D())        \n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50, X_train = X_train):\n",
    "\n",
    "        # Load the dataset\n",
    "        #(X_train, _), (_, _) = mnist.load_data()        \n",
    "        # Rescale -1 to 1\n",
    "        #X_train = (X_train / 127.5) - 1.\n",
    "        X_train = (X_train)/255.0\n",
    "        #X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        import time\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "            startTime = time.time()\n",
    "            # Select a random half of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            #self.discriminator.trainable = True\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator (wants discriminator to mistake images as real)\n",
    "            #self.discriminator.trainable = False \n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0 or epoch == epochs - 1 :    \n",
    "                cnt = 0\n",
    "                #gen_imgs = np.uint8(255 * gen_imgs)\n",
    "                for i in range(0,10):\n",
    "                    #plt.imshow(gen_imgs[cnt, :,:,0])#, cmap='gray')                    \n",
    "                    cv2.imwrite('fake_img/fake_{0}_{1}_acc_{2}per.png'.format(epoch,i,100*d_loss[1]),(cv2.cvtColor(np.uint8(255 * gen_imgs[cnt, :,:,:]), cv2.COLOR_RGB2BGR)))\n",
    "                    #cv2.imwrite('fake_img/fake_{0}_{1}.png'.format(epoch,i),np.uint8(255 * gen_imgs[cnt, :,:,:]))\n",
    "                    #print(np.uint8(255 * gen_imgs[cnt, :,:,0]))\n",
    "                    cnt += 1\n",
    "                #self.save_imgs(epoch)\n",
    "                self.save_model_weights()\n",
    "\n",
    "            endTime = time.time() - startTime\n",
    "            print('- epoch during time : {}sec'.format(round(endTime,4)))\n",
    "            \n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        #gen_imgs = (0.5 * gen_imgs + 0.5)* 127.5\n",
    "        gen_imgs = np.uint8(255 * gen_imgs)\n",
    "\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0])#, cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"fake_img/fake_{}.png\".format(epoch))\n",
    "        plt.close()\n",
    "        \n",
    "    def save_model_weights(self): \n",
    "        self.generator.save_weights('gan_g_weights.h5') \n",
    "        self.discriminator.save_weights('gan_d_weights.h5')\n",
    "        self.combined.save_weights('gan_combined_weights.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    dcgan.train(epochs=6000, batch_size=256, save_interval=10,X_train=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1000,1004):    \n",
    "    plt.imshow((cv2.cvtColor((cv2.cvtColor(X[:,:,:,:][i], cv2.COLOR_RGB2BGR)), cv2.COLOR_RGB2BGR)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bited44610ecb0349f4839292f36748c9e6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 313,
   "position": {
    "height": "40px",
    "left": "1296px",
    "right": "20px",
    "top": "117px",
    "width": "519px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
